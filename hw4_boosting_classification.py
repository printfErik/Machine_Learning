# -*- coding: utf-8 -*-
"""hw4_boosting_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16iUZcVOxJuL_ncsWbPkEx9lIh9K9dict
"""

from test_error_rate import error_rate
import numpy as np
import matplotlib.pyplot as plt

# read data
true_values = np.genfromtxt('true_values_classification.txt', delimiter=',')
true_values = np.expand_dims(true_values, axis=1)

# compute threshold for checking if weak learner is good 
threshold = 0
# compute the average threshold
for i in range(100):
  np.random.shuffle(true_values)
  threshold += error_rate(true_values)
threshold = threshold/100

# init data
errors = [0] * 10000 # error stores data error rate
h = [0] * 10000 # h is weak learner
percentage = np.sum(true_values == 0) / len(true_values)

# Keep adding weak learner to our model
i = 0
while i < 10000:
  np.random.shuffle(true_values)
  if error_rate(true_values) < threshold:
    h[i] = np.copy(true_values)
    new_h = np.copy(h[0])
    if i != 0:     
      for j in range(1, i):
          new_h += h[j]
      new_h = new_h / i
      to_check = np.percentile(new_h, percentage*100)
      new_h[new_h < to_check] = 0
      new_h[new_h >= to_check] = 1
    errors[i] = error_rate(new_h)
    print(errors[i])
    i += 1
    
# Plotting
plt.plot(errors)
plt.title('Error by Different Number of Weak Learners')
plt.xlabel('Number of Weak Learners')
plt.ylabel('Error Rate')
plt.show()